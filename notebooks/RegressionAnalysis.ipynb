{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align:center\">Regression Analysis for the California Housing census</h1>\n",
    "\n",
    "<p style=\"text-align:center\">Author: Jose Pena</p>\n",
    "<p style=\"text-align:center\">Github: <a href=\"https://github.com/JoseJuan98\">JoseJuan98</a></p>\n",
    "<br>\n",
    "\n",
    "------------------------------------------------------------------------------------------------\n",
    "\n",
    "<br>\n",
    "\n",
    "## Aims\n",
    "\n",
    "The aim of this notebook is to demonstrate the data regression skills leveraging a wide variety of tools, but also this report focuses on present findings, insights, and next steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------\n",
    "\n",
    "## Instructions:\n",
    "\n",
    "This exercise will demonstrate the data regression skills. You are expected to leverage a wide variety of tools, but also this report should focus on present findings, insights, and next steps. You may include some visuals from your code output, but this report is intended as a summary of your findings, not as a code review.\n",
    "\n",
    "The development will center around 5 main points:\n",
    "\n",
    "1.  Does the report include a section describing the data?\n",
    "2.  Does the report include a paragraph detailing the main objective(s) of this analysis?\n",
    "3.  Does the report include a section with variations of linear regression models and specifies which one is the model that best suits the main objective(s) of this analysis.\n",
    "4.  Does the report include a clear and well-presented section with key findings related to the main objective(s) of the analysis?\n",
    "5.  Does the report highlight possible flaws in the model and a plan of action to revisit this analysis with additional data or different predictive modeling techniques?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have selected a data set, you will produce the deliverables listed below and submit them to one of your peers for review. Treat this exercise as an opportunity to produce analysis that are ready to highlight your analytical skills for a senior audience, for example, the Chief Data Officer, or the Head of Analytics at your company.\n",
    "Sections required in your report:\n",
    "\n",
    "*   Main objective of the analysis that specifies whether your model will be focused on prediction or interpretation.\n",
    "*   Brief description of the data set you chose and a summary of its attributes.\n",
    "*   Brief summary of data exploration and actions taken for data cleaning and feature engineering.\n",
    "*   Summary of training at least three linear regression models which should be variations that cover using a simple  linear regression as a baseline, adding polynomial effects, and using a regularization regression. Preferably, all use the same training and test splits, or the same cross-validation method.\n",
    "*   A paragraph explaining which of your regressions you recommend as a final model that best fits your needs in terms of accuracy and explainability.\n",
    "*   Summary Key Findings and Insights, which walks your reader through the main drivers of your model and insights from your data derived from your linear regression model.\n",
    "*   Suggestions for next steps in analyzing this data, which may include suggesting revisiting this model adding specific data features to achieve a better explanation or a better prediction.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "-------------------------------------------"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Setup\n",
    "\n",
    "For this Regression Data Analysis project the following libraries will be used:\n",
    "\n",
    "*   [`pandas`](https://pandas.pydata.org/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0232ENSkillsNetwork30654641-2021-01-01) for managing the data.\n",
    "*   [`numpy`](https://numpy.org/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0232ENSkillsNetwork30654641-2021-01-01) for mathematical operations.\n",
    "*   [`seaborn`](https://seaborn.pydata.org/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0232ENSkillsNetwork30654641-2021-01-01) for visualizing the data.\n",
    "*   [`matplotlib`](https://matplotlib.org/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0232ENSkillsNetwork30654641-2021-01-01) for visualizing the data.\n",
    "*   [`sklearn`](https://scikit-learn.org/stable/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0232ENSkillsNetwork30654641-2021-01-01) for machine learning related functions.\n",
    "\n",
    "## Imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy\n",
    "import seaborn\n",
    "\n",
    "from scipy.stats import boxcox, ttest_ind\n",
    "from matplotlib import pyplot\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# utils.py\n",
    "from src.utils import fetch_housing_data, HOUSING_URL, HOUSING_PATH, plot_scatters, \\\n",
    "    plot_univariate_boxplots, remove_outliers_iqr, prepare_data, TARGET"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Setting up some options:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Display and store plot within the notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# Show all columns when displaying dataframe\n",
    "pandas.options.display.max_columns = None"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    " Load data, if it wasn't downloaded before it will fetch it from the URL specified, otherwise will load it from a local '.csv' file."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "data = fetch_housing_data(url=HOUSING_URL,\n",
    "                          path=HOUSING_PATH)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. About the Data\n",
    "\n",
    "This California Housing dataset is available from [Lu√≠s Torgo's page](https://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html) (University of Porto).\n",
    "\n",
    "This dataset appeared in a 1997 paper titled Sparse Spatial Autoregressions by Pace, R. Kelley and Ronald Barry, published in the Statistics and Probability Letters journal. They built it using the 1990 California census data. It contains one row per census block group. A block group is the smallest geographical unit for which the U.S. Census Bureau publishes sample data (a block group typically has a population of 600 to 3,000 people).\n",
    "\n",
    "The target variable or dependent variable for this anlysis will be the `median_house_value`, which describes median price of the houses per block group.\n",
    "\n",
    "**Shape of the dataset**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "(20640, 10)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**List of columns**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "['longitude',\n 'latitude',\n 'housing_median_age',\n 'total_rooms',\n 'total_bedrooms',\n 'population',\n 'households',\n 'median_income',\n 'median_house_value',\n 'ocean_proximity']"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns.to_list()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**First 5 rows of the dataset**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n0    -122.23     37.88                41.0        880.0           129.0   \n1    -122.22     37.86                21.0       7099.0          1106.0   \n2    -122.24     37.85                52.0       1467.0           190.0   \n3    -122.25     37.85                52.0       1274.0           235.0   \n4    -122.25     37.85                52.0       1627.0           280.0   \n\n   population  households  median_income  median_house_value ocean_proximity  \n0       322.0       126.0         8.3252            452600.0        NEAR BAY  \n1      2401.0      1138.0         8.3014            358500.0        NEAR BAY  \n2       496.0       177.0         7.2574            352100.0        NEAR BAY  \n3       558.0       219.0         5.6431            341300.0        NEAR BAY  \n4       565.0       259.0         3.8462            342200.0        NEAR BAY  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>longitude</th>\n      <th>latitude</th>\n      <th>housing_median_age</th>\n      <th>total_rooms</th>\n      <th>total_bedrooms</th>\n      <th>population</th>\n      <th>households</th>\n      <th>median_income</th>\n      <th>median_house_value</th>\n      <th>ocean_proximity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-122.23</td>\n      <td>37.88</td>\n      <td>41.0</td>\n      <td>880.0</td>\n      <td>129.0</td>\n      <td>322.0</td>\n      <td>126.0</td>\n      <td>8.3252</td>\n      <td>452600.0</td>\n      <td>NEAR BAY</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-122.22</td>\n      <td>37.86</td>\n      <td>21.0</td>\n      <td>7099.0</td>\n      <td>1106.0</td>\n      <td>2401.0</td>\n      <td>1138.0</td>\n      <td>8.3014</td>\n      <td>358500.0</td>\n      <td>NEAR BAY</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-122.24</td>\n      <td>37.85</td>\n      <td>52.0</td>\n      <td>1467.0</td>\n      <td>190.0</td>\n      <td>496.0</td>\n      <td>177.0</td>\n      <td>7.2574</td>\n      <td>352100.0</td>\n      <td>NEAR BAY</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-122.25</td>\n      <td>37.85</td>\n      <td>52.0</td>\n      <td>1274.0</td>\n      <td>235.0</td>\n      <td>558.0</td>\n      <td>219.0</td>\n      <td>5.6431</td>\n      <td>341300.0</td>\n      <td>NEAR BAY</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-122.25</td>\n      <td>37.85</td>\n      <td>52.0</td>\n      <td>1627.0</td>\n      <td>280.0</td>\n      <td>565.0</td>\n      <td>259.0</td>\n      <td>3.8462</td>\n      <td>342200.0</td>\n      <td>NEAR BAY</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Non-null values count, type of feature and memory usage**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20640 entries, 0 to 20639\n",
      "Data columns (total 10 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   longitude           20640 non-null  float64\n",
      " 1   latitude            20640 non-null  float64\n",
      " 2   housing_median_age  20640 non-null  float64\n",
      " 3   total_rooms         20640 non-null  float64\n",
      " 4   total_bedrooms      20433 non-null  float64\n",
      " 5   population          20640 non-null  float64\n",
      " 6   households          20640 non-null  float64\n",
      " 7   median_income       20640 non-null  float64\n",
      " 8   median_house_value  20640 non-null  float64\n",
      " 9   ocean_proximity     20640 non-null  object \n",
      "dtypes: float64(9), object(1)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Statistical properties of the dataset**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "           longitude      latitude  housing_median_age   total_rooms  \\\ncount   20640.000000  20640.000000        20640.000000  20640.000000   \nunique           NaN           NaN                 NaN           NaN   \ntop              NaN           NaN                 NaN           NaN   \nfreq             NaN           NaN                 NaN           NaN   \nmean     -119.569704     35.631861           28.639486   2635.763081   \nstd         2.003532      2.135952           12.585558   2181.615252   \nmin      -124.350000     32.540000            1.000000      2.000000   \n25%      -121.800000     33.930000           18.000000   1447.750000   \n50%      -118.490000     34.260000           29.000000   2127.000000   \n75%      -118.010000     37.710000           37.000000   3148.000000   \nmax      -114.310000     41.950000           52.000000  39320.000000   \n\n        total_bedrooms    population    households  median_income  \\\ncount     20433.000000  20640.000000  20640.000000   20640.000000   \nunique             NaN           NaN           NaN            NaN   \ntop                NaN           NaN           NaN            NaN   \nfreq               NaN           NaN           NaN            NaN   \nmean        537.870553   1425.476744    499.539680       3.870671   \nstd         421.385070   1132.462122    382.329753       1.899822   \nmin           1.000000      3.000000      1.000000       0.499900   \n25%         296.000000    787.000000    280.000000       2.563400   \n50%         435.000000   1166.000000    409.000000       3.534800   \n75%         647.000000   1725.000000    605.000000       4.743250   \nmax        6445.000000  35682.000000   6082.000000      15.000100   \n\n        median_house_value ocean_proximity  \ncount         20640.000000           20640  \nunique                 NaN               5  \ntop                    NaN       <1H OCEAN  \nfreq                   NaN            9136  \nmean         206855.816909             NaN  \nstd          115395.615874             NaN  \nmin           14999.000000             NaN  \n25%          119600.000000             NaN  \n50%          179700.000000             NaN  \n75%          264725.000000             NaN  \nmax          500001.000000             NaN  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>longitude</th>\n      <th>latitude</th>\n      <th>housing_median_age</th>\n      <th>total_rooms</th>\n      <th>total_bedrooms</th>\n      <th>population</th>\n      <th>households</th>\n      <th>median_income</th>\n      <th>median_house_value</th>\n      <th>ocean_proximity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>20640.000000</td>\n      <td>20640.000000</td>\n      <td>20640.000000</td>\n      <td>20640.000000</td>\n      <td>20433.000000</td>\n      <td>20640.000000</td>\n      <td>20640.000000</td>\n      <td>20640.000000</td>\n      <td>20640.000000</td>\n      <td>20640</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>&lt;1H OCEAN</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>9136</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>-119.569704</td>\n      <td>35.631861</td>\n      <td>28.639486</td>\n      <td>2635.763081</td>\n      <td>537.870553</td>\n      <td>1425.476744</td>\n      <td>499.539680</td>\n      <td>3.870671</td>\n      <td>206855.816909</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>2.003532</td>\n      <td>2.135952</td>\n      <td>12.585558</td>\n      <td>2181.615252</td>\n      <td>421.385070</td>\n      <td>1132.462122</td>\n      <td>382.329753</td>\n      <td>1.899822</td>\n      <td>115395.615874</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>-124.350000</td>\n      <td>32.540000</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>3.000000</td>\n      <td>1.000000</td>\n      <td>0.499900</td>\n      <td>14999.000000</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>-121.800000</td>\n      <td>33.930000</td>\n      <td>18.000000</td>\n      <td>1447.750000</td>\n      <td>296.000000</td>\n      <td>787.000000</td>\n      <td>280.000000</td>\n      <td>2.563400</td>\n      <td>119600.000000</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>-118.490000</td>\n      <td>34.260000</td>\n      <td>29.000000</td>\n      <td>2127.000000</td>\n      <td>435.000000</td>\n      <td>1166.000000</td>\n      <td>409.000000</td>\n      <td>3.534800</td>\n      <td>179700.000000</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>-118.010000</td>\n      <td>37.710000</td>\n      <td>37.000000</td>\n      <td>3148.000000</td>\n      <td>647.000000</td>\n      <td>1725.000000</td>\n      <td>605.000000</td>\n      <td>4.743250</td>\n      <td>264725.000000</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>-114.310000</td>\n      <td>41.950000</td>\n      <td>52.000000</td>\n      <td>39320.000000</td>\n      <td>6445.000000</td>\n      <td>35682.000000</td>\n      <td>6082.000000</td>\n      <td>15.000100</td>\n      <td>500001.000000</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe(include='all')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As it was analyzed in the previous exercise of Exploratory Data Analysis ([notebook](ExploratoryDataAnalysis.ipynb), [report](/reports/ExploratoryDataAnalysis.pdf)) the actions taken for Data Cleaning and Feature Engineering are:\n",
    "* Target normalization\n",
    "* Handling missing values\n",
    "* Handling outliers\n",
    "* Encoding categorical variables\n",
    "* Scaling continuous variables\n",
    "\n",
    "And these actions are encapsulated in the method `prepare_data()` from the `utils/data_transformations.py`, but first\n",
    "the data must be split to create the train and test set to avoid overfitting and inaccurate evaluation."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "train_set, test_set = train_test_split(data, random_state=42, test_size=0.3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "(14448, 10)"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "(6192, 10)"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "______________________________ Preparing Data ______________________________\n",
      "\t-> Target normalization. \n",
      "\t\tSkewness: \n",
      "                              Old       : 0.9833. \n",
      "                              Current   : -0.0085\n",
      "\n",
      "\t-> Handling missing values. \n",
      "\t\tMissing values of `total_bedrooms`:\n",
      "                              Before    : 0\n",
      "                              After     : 0\n",
      "\n",
      "\t-> Handling outliers.\n",
      "\t-> Encoding categorical variables.\n",
      "\t-> Scaling continuous variables.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_set, lamb = prepare_data(data=train_set, target=TARGET, verbose=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Objectives\n",
    "\n",
    "This exercise focuses in the predictions of the models to have a better understanding of the features and its impact in the target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# TODO\n",
    "\n",
    "- Summary of training at least three linear regression models which should be variations that cover using a simple linear regression as a baseline, adding polynomial effects, and using a regularization regression. Preferably, all use the same training and test splits, or the same cross-validation method.\n",
    "- A paragraph explaining which of your regressions you recommend as a final model that best fits your needs in terms of accuracy and explainability.\n",
    "- Summary Key Findings and Insights, which walks your reader through the main drivers of your model and insights from your data derived from your linear regression model.\n",
    "- Suggestions for next steps in analyzing this data, which may include suggesting revisiting this model adding specific data features to achieve a better explanation or a better prediction."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Linear Regression Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_set.drop('median_house_value', axis=1)\n",
    "y = train_set['median_house_value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(shuffle=True, random_state=42, n_splits=5)\n",
    "lr = GridSearchCV(estimator=LinearRegression(n_jobs=-1),\n",
    "                  n_jobs=-1,\n",
    "                  verbose=1,\n",
    "                  param_grid={},\n",
    "                  cv=kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "longitude                       0\nlatitude                        0\nhousing_median_age              0\ntotal_rooms                   913\ntotal_bedrooms                916\npopulation                    835\nhouseholds                    862\nmedian_income                 586\nocean_proximity_<1H OCEAN       0\nocean_proximity_INLAND          0\nocean_proximity_ISLAND          0\nocean_proximity_NEAR BAY        0\nocean_proximity_NEAR OCEAN      0\ndtype: int64"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/goldenfox/Work/Projects/ML_Projects/CaliforniaHousingCensusCase/venv/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/goldenfox/Work/Projects/ML_Projects/CaliforniaHousingCensusCase/venv/lib/python3.10/site-packages/sklearn/linear_model/_base.py\", line 648, in fit\n    X, y = self._validate_data(\n  File \"/home/goldenfox/Work/Projects/ML_Projects/CaliforniaHousingCensusCase/venv/lib/python3.10/site-packages/sklearn/base.py\", line 565, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/home/goldenfox/Work/Projects/ML_Projects/CaliforniaHousingCensusCase/venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1106, in check_X_y\n    X = check_array(\n  File \"/home/goldenfox/Work/Projects/ML_Projects/CaliforniaHousingCensusCase/venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n    _assert_all_finite(\n  File \"/home/goldenfox/Work/Projects/ML_Projects/CaliforniaHousingCensusCase/venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLinearRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[17], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mlr\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Work/Projects/ML_Projects/CaliforniaHousingCensusCase/venv/lib/python3.10/site-packages/sklearn/model_selection/_search.py:874\u001B[0m, in \u001B[0;36mBaseSearchCV.fit\u001B[0;34m(self, X, y, groups, **fit_params)\u001B[0m\n\u001B[1;32m    868\u001B[0m     results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_format_results(\n\u001B[1;32m    869\u001B[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001B[1;32m    870\u001B[0m     )\n\u001B[1;32m    872\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m results\n\u001B[0;32m--> 874\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_search\u001B[49m\u001B[43m(\u001B[49m\u001B[43mevaluate_candidates\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    876\u001B[0m \u001B[38;5;66;03m# multimetric is determined here because in the case of a callable\u001B[39;00m\n\u001B[1;32m    877\u001B[0m \u001B[38;5;66;03m# self.scoring the return type is only known after calling\u001B[39;00m\n\u001B[1;32m    878\u001B[0m first_test_score \u001B[38;5;241m=\u001B[39m all_out[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest_scores\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[0;32m~/Work/Projects/ML_Projects/CaliforniaHousingCensusCase/venv/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1388\u001B[0m, in \u001B[0;36mGridSearchCV._run_search\u001B[0;34m(self, evaluate_candidates)\u001B[0m\n\u001B[1;32m   1386\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_run_search\u001B[39m(\u001B[38;5;28mself\u001B[39m, evaluate_candidates):\n\u001B[1;32m   1387\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001B[39;00m\n\u001B[0;32m-> 1388\u001B[0m     \u001B[43mevaluate_candidates\u001B[49m\u001B[43m(\u001B[49m\u001B[43mParameterGrid\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparam_grid\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Work/Projects/ML_Projects/CaliforniaHousingCensusCase/venv/lib/python3.10/site-packages/sklearn/model_selection/_search.py:851\u001B[0m, in \u001B[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001B[0;34m(candidate_params, cv, more_results)\u001B[0m\n\u001B[1;32m    844\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(out) \u001B[38;5;241m!=\u001B[39m n_candidates \u001B[38;5;241m*\u001B[39m n_splits:\n\u001B[1;32m    845\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    846\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcv.split and cv.get_n_splits returned \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    847\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minconsistent results. Expected \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    848\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msplits, got \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(n_splits, \u001B[38;5;28mlen\u001B[39m(out) \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m/\u001B[39m n_candidates)\n\u001B[1;32m    849\u001B[0m     )\n\u001B[0;32m--> 851\u001B[0m \u001B[43m_warn_or_raise_about_fit_failures\u001B[49m\u001B[43m(\u001B[49m\u001B[43mout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43merror_score\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    853\u001B[0m \u001B[38;5;66;03m# For callable self.scoring, the return type is only know after\u001B[39;00m\n\u001B[1;32m    854\u001B[0m \u001B[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001B[39;00m\n\u001B[1;32m    855\u001B[0m \u001B[38;5;66;03m# can now be inserted with the correct key. The type checking\u001B[39;00m\n\u001B[1;32m    856\u001B[0m \u001B[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001B[39;00m\n\u001B[1;32m    857\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m callable(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mscoring):\n",
      "File \u001B[0;32m~/Work/Projects/ML_Projects/CaliforniaHousingCensusCase/venv/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:367\u001B[0m, in \u001B[0;36m_warn_or_raise_about_fit_failures\u001B[0;34m(results, error_score)\u001B[0m\n\u001B[1;32m    360\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m num_failed_fits \u001B[38;5;241m==\u001B[39m num_fits:\n\u001B[1;32m    361\u001B[0m     all_fits_failed_message \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m    362\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mAll the \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnum_fits\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m fits failed.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    363\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIt is very likely that your model is misconfigured.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    364\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mYou can try to debug the error by setting error_score=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mraise\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    365\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBelow are more details about the failures:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mfit_errors_summary\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    366\u001B[0m     )\n\u001B[0;32m--> 367\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(all_fits_failed_message)\n\u001B[1;32m    369\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    370\u001B[0m     some_fits_failed_message \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m    371\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mnum_failed_fits\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m fits failed out of a total of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnum_fits\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    372\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe score on these train-test partitions for these parameters\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    376\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBelow are more details about the failures:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mfit_errors_summary\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    377\u001B[0m     )\n",
      "\u001B[0;31mValueError\u001B[0m: \nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/goldenfox/Work/Projects/ML_Projects/CaliforniaHousingCensusCase/venv/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/goldenfox/Work/Projects/ML_Projects/CaliforniaHousingCensusCase/venv/lib/python3.10/site-packages/sklearn/linear_model/_base.py\", line 648, in fit\n    X, y = self._validate_data(\n  File \"/home/goldenfox/Work/Projects/ML_Projects/CaliforniaHousingCensusCase/venv/lib/python3.10/site-packages/sklearn/base.py\", line 565, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/home/goldenfox/Work/Projects/ML_Projects/CaliforniaHousingCensusCase/venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1106, in check_X_y\n    X = check_array(\n  File \"/home/goldenfox/Work/Projects/ML_Projects/CaliforniaHousingCensusCase/venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n    _assert_all_finite(\n  File \"/home/goldenfox/Work/Projects/ML_Projects/CaliforniaHousingCensusCase/venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLinearRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n"
     ]
    }
   ],
   "source": [
    "lr.fit(X=X, y=y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "numpy.float64"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X[X.total_bedrooms.isna()].total_bedrooms.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "False"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[X.total_bedrooms.isna()].total_bedrooms.iloc[0] is pandas.NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "False"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[X.total_bedrooms.isna()].total_bedrooms.iloc[0] == numpy.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "15283   NaN\n13019   NaN\n3090    NaN\n14558   NaN\n17132   NaN\n         ..\n8838    NaN\n8666    NaN\n6420    NaN\n4426    NaN\n15795   NaN\nName: total_bedrooms, Length: 916, dtype: float64"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[X.total_bedrooms.isna()].total_bedrooms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Insights and key findings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Next Steps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Author"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "<p>Author: Jose Pena</p>\n",
    "<p>Github: <a href=\"https://github.com/JoseJuan98\">JoseJuan98</a></p>"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Change Log\n",
    "| Date (YYYY-MM-DD) | Version | Changed By | Change Description   |\n",
    "|-------------------| ------- | ---------- | -------------------- |\n",
    "| 2022-11-27        | 1.0     | Jose       | First version        |\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align:center\">Regression Analysis for the California Housing census</h1>\n",
    "\n",
    "<p style=\"text-align:center\">Author: Jose Pena</p>\n",
    "<p style=\"text-align:center\">Github: <a href=\"https://github.com/JoseJuan98\">JoseJuan98</a></p>\n",
    "<br>\n",
    "\n",
    "------------------------------------------------------------------------------------------------\n",
    "\n",
    "<br>\n",
    "\n",
    "## Aims\n",
    "\n",
    "The aim of this notebook is to demonstrate the data regression skills leveraging a wide variety of tools, but also this report focuses on present findings, insights, and next steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------\n",
    "\n",
    "## Instructions:\n",
    "\n",
    "This exercise will demonstrate the data regression skills. You are expected to leverage a wide variety of tools, but also this report should focus on present findings, insights, and next steps. You may include some visuals from your code output, but this report is intended as a summary of your findings, not as a code review.\n",
    "\n",
    "The development will center around 5 main points:\n",
    "\n",
    "1.  Does the report include a section describing the data?\n",
    "2.  Does the report include a paragraph detailing the main objective(s) of this analysis?\n",
    "3.  Does the report include a section with variations of linear regression models and specifies which one is the model that best suits the main objective(s) of this analysis.\n",
    "4.  Does the report include a clear and well-presented section with key findings related to the main objective(s) of the analysis?\n",
    "5.  Does the report highlight possible flaws in the model and a plan of action to revisit this analysis with additional data or different predictive modeling techniques?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have selected a data set, you will produce the deliverables listed below and submit them to one of your peers for review. Treat this exercise as an opportunity to produce analysis that are ready to highlight your analytical skills for a senior audience, for example, the Chief Data Officer, or the Head of Analytics at your company.\n",
    "Sections required in your report:\n",
    "\n",
    "*   Main objective of the analysis that specifies whether your model will be focused on prediction or interpretation.\n",
    "*   Brief description of the data set you chose and a summary of its attributes.\n",
    "*   Brief summary of data exploration and actions taken for data cleaning and feature engineering.\n",
    "*   Summary of training at least three linear regression models which should be variations that cover using a simple  linear regression as a baseline, adding polynomial effects, and using a regularization regression. Preferably, all use the same training and test splits, or the same cross-validation method.\n",
    "*   A paragraph explaining which of your regressions you recommend as a final model that best fits your needs in terms of accuracy and explainability.\n",
    "*   Summary Key Findings and Insights, which walks your reader through the main drivers of your model and insights from your data derived from your linear regression model.\n",
    "*   Suggestions for next steps in analyzing this data, which may include suggesting revisiting this model adding specific data features to achieve a better explanation or a better prediction.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "-------------------------------------------"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Setup\n",
    "\n",
    "For this Regression Data Analysis project the following libraries will be used:\n",
    "\n",
    "*   [`pandas`](https://pandas.pydata.org/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0232ENSkillsNetwork30654641-2021-01-01) for managing the data.\n",
    "*   [`numpy`](https://numpy.org/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0232ENSkillsNetwork30654641-2021-01-01) for mathematical operations.\n",
    "*   [`seaborn`](https://seaborn.pydata.org/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0232ENSkillsNetwork30654641-2021-01-01) for visualizing the data.\n",
    "*   [`matplotlib`](https://matplotlib.org/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0232ENSkillsNetwork30654641-2021-01-01) for visualizing the data.\n",
    "*   [`sklearn`](https://scikit-learn.org/stable/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0232ENSkillsNetwork30654641-2021-01-01) for machine learning related functions.\n",
    "\n",
    "## Imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, ElasticNetCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "from src.utils.data_transformations import preprocess_data\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# utils.py\n",
    "from src.utils import fetch_housing_data, HOUSING_URL, HOUSING_PATH, TARGET"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Setting up some options:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# Display and store plot within the notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# Show all columns when displaying dataframe\n",
    "pandas.options.display.max_columns = None"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    " Load data, if it wasn't downloaded before it will fetch it from the URL specified, otherwise will load it from a local '.csv' file."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "data = fetch_housing_data(url=HOUSING_URL,\n",
    "                          path=HOUSING_PATH)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. About the Data\n",
    "\n",
    "This California Housing dataset is available from [Lu√≠s Torgo's page](https://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html) (University of Porto).\n",
    "\n",
    "This dataset appeared in a 1997 paper titled Sparse Spatial Autoregressions by Pace, R. Kelley and Ronald Barry, published in the Statistics and Probability Letters journal. They built it using the 1990 California census data. It contains one row per census block group. A block group is the smallest geographical unit for which the U.S. Census Bureau publishes sample data (a block group typically has a population of 600 to 3,000 people).\n",
    "\n",
    "The target variable or dependent variable for this anlysis will be the `median_house_value`, which describes median price of the houses per block group.\n",
    "\n",
    "**Shape of the dataset**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "(20640, 10)"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**List of columns**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "['longitude',\n 'latitude',\n 'housing_median_age',\n 'total_rooms',\n 'total_bedrooms',\n 'population',\n 'households',\n 'median_income',\n 'median_house_value',\n 'ocean_proximity']"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns.to_list()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**First 5 rows of the dataset**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n0    -122.23     37.88                41.0        880.0           129.0   \n1    -122.22     37.86                21.0       7099.0          1106.0   \n2    -122.24     37.85                52.0       1467.0           190.0   \n3    -122.25     37.85                52.0       1274.0           235.0   \n4    -122.25     37.85                52.0       1627.0           280.0   \n\n   population  households  median_income  median_house_value ocean_proximity  \n0       322.0       126.0         8.3252            452600.0        NEAR BAY  \n1      2401.0      1138.0         8.3014            358500.0        NEAR BAY  \n2       496.0       177.0         7.2574            352100.0        NEAR BAY  \n3       558.0       219.0         5.6431            341300.0        NEAR BAY  \n4       565.0       259.0         3.8462            342200.0        NEAR BAY  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>longitude</th>\n      <th>latitude</th>\n      <th>housing_median_age</th>\n      <th>total_rooms</th>\n      <th>total_bedrooms</th>\n      <th>population</th>\n      <th>households</th>\n      <th>median_income</th>\n      <th>median_house_value</th>\n      <th>ocean_proximity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-122.23</td>\n      <td>37.88</td>\n      <td>41.0</td>\n      <td>880.0</td>\n      <td>129.0</td>\n      <td>322.0</td>\n      <td>126.0</td>\n      <td>8.3252</td>\n      <td>452600.0</td>\n      <td>NEAR BAY</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-122.22</td>\n      <td>37.86</td>\n      <td>21.0</td>\n      <td>7099.0</td>\n      <td>1106.0</td>\n      <td>2401.0</td>\n      <td>1138.0</td>\n      <td>8.3014</td>\n      <td>358500.0</td>\n      <td>NEAR BAY</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-122.24</td>\n      <td>37.85</td>\n      <td>52.0</td>\n      <td>1467.0</td>\n      <td>190.0</td>\n      <td>496.0</td>\n      <td>177.0</td>\n      <td>7.2574</td>\n      <td>352100.0</td>\n      <td>NEAR BAY</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-122.25</td>\n      <td>37.85</td>\n      <td>52.0</td>\n      <td>1274.0</td>\n      <td>235.0</td>\n      <td>558.0</td>\n      <td>219.0</td>\n      <td>5.6431</td>\n      <td>341300.0</td>\n      <td>NEAR BAY</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-122.25</td>\n      <td>37.85</td>\n      <td>52.0</td>\n      <td>1627.0</td>\n      <td>280.0</td>\n      <td>565.0</td>\n      <td>259.0</td>\n      <td>3.8462</td>\n      <td>342200.0</td>\n      <td>NEAR BAY</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Non-null values count, type of feature and memory usage**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20640 entries, 0 to 20639\n",
      "Data columns (total 10 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   longitude           20640 non-null  float64\n",
      " 1   latitude            20640 non-null  float64\n",
      " 2   housing_median_age  20640 non-null  float64\n",
      " 3   total_rooms         20640 non-null  float64\n",
      " 4   total_bedrooms      20433 non-null  float64\n",
      " 5   population          20640 non-null  float64\n",
      " 6   households          20640 non-null  float64\n",
      " 7   median_income       20640 non-null  float64\n",
      " 8   median_house_value  20640 non-null  float64\n",
      " 9   ocean_proximity     20640 non-null  object \n",
      "dtypes: float64(9), object(1)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Statistical properties of the dataset**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "           longitude      latitude  housing_median_age   total_rooms  \\\ncount   20640.000000  20640.000000        20640.000000  20640.000000   \nunique           NaN           NaN                 NaN           NaN   \ntop              NaN           NaN                 NaN           NaN   \nfreq             NaN           NaN                 NaN           NaN   \nmean     -119.569704     35.631861           28.639486   2635.763081   \nstd         2.003532      2.135952           12.585558   2181.615252   \nmin      -124.350000     32.540000            1.000000      2.000000   \n25%      -121.800000     33.930000           18.000000   1447.750000   \n50%      -118.490000     34.260000           29.000000   2127.000000   \n75%      -118.010000     37.710000           37.000000   3148.000000   \nmax      -114.310000     41.950000           52.000000  39320.000000   \n\n        total_bedrooms    population    households  median_income  \\\ncount     20433.000000  20640.000000  20640.000000   20640.000000   \nunique             NaN           NaN           NaN            NaN   \ntop                NaN           NaN           NaN            NaN   \nfreq               NaN           NaN           NaN            NaN   \nmean        537.870553   1425.476744    499.539680       3.870671   \nstd         421.385070   1132.462122    382.329753       1.899822   \nmin           1.000000      3.000000      1.000000       0.499900   \n25%         296.000000    787.000000    280.000000       2.563400   \n50%         435.000000   1166.000000    409.000000       3.534800   \n75%         647.000000   1725.000000    605.000000       4.743250   \nmax        6445.000000  35682.000000   6082.000000      15.000100   \n\n        median_house_value ocean_proximity  \ncount         20640.000000           20640  \nunique                 NaN               5  \ntop                    NaN       <1H OCEAN  \nfreq                   NaN            9136  \nmean         206855.816909             NaN  \nstd          115395.615874             NaN  \nmin           14999.000000             NaN  \n25%          119600.000000             NaN  \n50%          179700.000000             NaN  \n75%          264725.000000             NaN  \nmax          500001.000000             NaN  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>longitude</th>\n      <th>latitude</th>\n      <th>housing_median_age</th>\n      <th>total_rooms</th>\n      <th>total_bedrooms</th>\n      <th>population</th>\n      <th>households</th>\n      <th>median_income</th>\n      <th>median_house_value</th>\n      <th>ocean_proximity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>20640.000000</td>\n      <td>20640.000000</td>\n      <td>20640.000000</td>\n      <td>20640.000000</td>\n      <td>20433.000000</td>\n      <td>20640.000000</td>\n      <td>20640.000000</td>\n      <td>20640.000000</td>\n      <td>20640.000000</td>\n      <td>20640</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>&lt;1H OCEAN</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>9136</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>-119.569704</td>\n      <td>35.631861</td>\n      <td>28.639486</td>\n      <td>2635.763081</td>\n      <td>537.870553</td>\n      <td>1425.476744</td>\n      <td>499.539680</td>\n      <td>3.870671</td>\n      <td>206855.816909</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>2.003532</td>\n      <td>2.135952</td>\n      <td>12.585558</td>\n      <td>2181.615252</td>\n      <td>421.385070</td>\n      <td>1132.462122</td>\n      <td>382.329753</td>\n      <td>1.899822</td>\n      <td>115395.615874</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>-124.350000</td>\n      <td>32.540000</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>3.000000</td>\n      <td>1.000000</td>\n      <td>0.499900</td>\n      <td>14999.000000</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>-121.800000</td>\n      <td>33.930000</td>\n      <td>18.000000</td>\n      <td>1447.750000</td>\n      <td>296.000000</td>\n      <td>787.000000</td>\n      <td>280.000000</td>\n      <td>2.563400</td>\n      <td>119600.000000</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>-118.490000</td>\n      <td>34.260000</td>\n      <td>29.000000</td>\n      <td>2127.000000</td>\n      <td>435.000000</td>\n      <td>1166.000000</td>\n      <td>409.000000</td>\n      <td>3.534800</td>\n      <td>179700.000000</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>-118.010000</td>\n      <td>37.710000</td>\n      <td>37.000000</td>\n      <td>3148.000000</td>\n      <td>647.000000</td>\n      <td>1725.000000</td>\n      <td>605.000000</td>\n      <td>4.743250</td>\n      <td>264725.000000</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>-114.310000</td>\n      <td>41.950000</td>\n      <td>52.000000</td>\n      <td>39320.000000</td>\n      <td>6445.000000</td>\n      <td>35682.000000</td>\n      <td>6082.000000</td>\n      <td>15.000100</td>\n      <td>500001.000000</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe(include='all')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As it was analyzed in the previous exercise of Exploratory Data Analysis ([notebook](ExploratoryDataAnalysis.ipynb), [report](/reports/ExploratoryDataAnalysis.pdf)) the actions taken for Data Cleaning and Feature Engineering are:\n",
    "* Target normalization\n",
    "* Handling missing values\n",
    "* Handling outliers\n",
    "* Encoding categorical variables\n",
    "* Scaling continuous variables\n",
    "\n",
    "And these actions are encapsulated in the method `prepare_data()` from the `utils/data_transformations.py`, but first\n",
    "the data must be split to create the train and test set to avoid overfitting and inaccurate evaluation."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(data.drop(columns=[TARGET], axis=1),data[TARGET], random_state=42, test_size=0.3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "' Shape x_train (14448, 9) - y_train (14448,)'"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\" Shape x_train {x_train.shape} - y_train {y_train.shape}\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "' Shape x_test (6192, 9) - y_test (6192,)'"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\" Shape x_test {x_test.shape} - y_test {y_test.shape}\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Objectives\n",
    "\n",
    "This exercise focuses in the predictions of the models, so this approach compares $y_p$ with $y$ by **performance metrics**,\n",
    "which measure the quality of the model's predictions (closeness between $y_p$ and $y$).\n",
    "\n",
    "As this approach doesn't focus on interpretability there is a greater risk of having a Black-box model, so it's recommended\n",
    "also to explore an approach based in interpretation to have both."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# TODO\n",
    "\n",
    "- Summary of training at least three linear regression models which should be variations that cover using a simple linear regression as a baseline, adding polynomial effects, and using a regularization regression. Preferably, all use the same training and test splits, or the same cross-validation method.\n",
    "- A paragraph explaining which of your regressions you recommend as a final model that best fits your needs in terms of accuracy and explainability.\n",
    "- Summary Key Findings and Insights, which walks your reader through the main drivers of your model and insights from your data derived from your linear regression model.\n",
    "- Suggestions for next steps in analyzing this data, which may include suggesting revisiting this model adding specific data features to achieve a better explanation or a better prediction."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Linear Regression Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    return numpy.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "metrics = {}\n",
    "\n",
    "def add_metrics(metrics_report: dict, model_name: str, y_true, y_pred) -> dict:\n",
    "    \"\"\"\n",
    "\n",
    "    Args:\n",
    "        metrics_report:\n",
    "        model_name:\n",
    "        y_true:\n",
    "        y_pred:\n",
    "\n",
    "    Returns:\n",
    "        dict: per model\n",
    "                - MSE: penalizes big errors\n",
    "                - RMSE: standarize unit errors\n",
    "                - R2: proportion of variance (0,1) - The bigger better\n",
    "                - MAE: average of erros\n",
    "    \"\"\"\n",
    "    mse = mean_squared_error(y_true=y_true, y_pred=y_pred)\n",
    "    rmse = numpy.sqrt(mse)\n",
    "    r2 = r2_score(y_true=y_true, y_pred=y_pred)\n",
    "    mae = mean_absolute_error(y_true=y_true, y_pred=y_pred)\n",
    "\n",
    "    metrics_report[model_name] = {\n",
    "        'MSE': round(mse, 4),\n",
    "        'RMSE': round(rmse, 4),\n",
    "        'R2': round(r2, 4),\n",
    "        'MAE': round(mae, 4)\n",
    "    }\n",
    "    return metrics_report"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Preparing the data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cat cols: ['ocean_proximity'] \n",
      "\n",
      " Num cols: ['longitude', 'latitude', 'housing_median_age', 'total_rooms', 'total_bedrooms', 'population', 'households', 'median_income']\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "fit_transform() missing argument: y",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31m_RemoteTraceback\u001B[0m                          Traceback (most recent call last)",
      "\u001B[0;31m_RemoteTraceback\u001B[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/goldenfox/Work/Projects/ML_Projects/CaliforniaHousingCensusCase/venv/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py\", line 428, in _process_worker\n    r = call_item()\n  File \"/home/goldenfox/Work/Projects/ML_Projects/CaliforniaHousingCensusCase/venv/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py\", line 275, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"/home/goldenfox/Work/Projects/ML_Projects/CaliforniaHousingCensusCase/venv/lib/python3.10/site-packages/joblib/_parallel_backends.py\", line 620, in __call__\n    return self.func(*args, **kwargs)\n  File \"/home/goldenfox/Work/Projects/ML_Projects/CaliforniaHousingCensusCase/venv/lib/python3.10/site-packages/joblib/parallel.py\", line 288, in __call__\n    return [func(*args, **kwargs)\n  File \"/home/goldenfox/Work/Projects/ML_Projects/CaliforniaHousingCensusCase/venv/lib/python3.10/site-packages/joblib/parallel.py\", line 288, in <listcomp>\n    return [func(*args, **kwargs)\n  File \"/home/goldenfox/Work/Projects/ML_Projects/CaliforniaHousingCensusCase/venv/lib/python3.10/site-packages/sklearn/utils/parallel.py\", line 123, in __call__\n    return self.function(*args, **kwargs)\n  File \"/home/goldenfox/Work/Projects/ML_Projects/CaliforniaHousingCensusCase/venv/lib/python3.10/site-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n  File \"/home/goldenfox/Work/Projects/ML_Projects/CaliforniaHousingCensusCase/venv/lib/python3.10/site-packages/sklearn/pipeline.py\", line 445, in fit_transform\n    return last_step.fit_transform(Xt, y, **fit_params_last_step)\n  File \"/home/goldenfox/Work/Projects/ML_Projects/CaliforniaHousingCensusCase/venv/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 142, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/home/goldenfox/Work/Projects/ML_Projects/CaliforniaHousingCensusCase/venv/lib/python3.10/site-packages/category_encoders/utils.py\", line 445, in fit_transform\n    raise TypeError('fit_transform() missing argument: ''y''')\nTypeError: fit_transform() missing argument: y\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[26], line 4\u001B[0m\n\u001B[1;32m      1\u001B[0m vars_with_outliers \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmedian_income\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtotal_rooms\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtotal_bedrooms\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpopulation\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m      2\u001B[0m                       \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmedian_income\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhousing_median_age\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhouseholds\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m----> 4\u001B[0m x_train, y_train, preprocessor, _ \u001B[38;5;241m=\u001B[39m \u001B[43mpreprocess_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mx_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvariables_with_outliers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvars_with_outliers\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      5\u001B[0m x_test, y_test, _, _ \u001B[38;5;241m=\u001B[39m preprocess_data(X\u001B[38;5;241m=\u001B[39mx_test, y\u001B[38;5;241m=\u001B[39my_test, preprocessor\u001B[38;5;241m=\u001B[39mpreprocessor, variables_with_outliers\u001B[38;5;241m=\u001B[39mvars_with_outliers)\n",
      "File \u001B[0;32m~/Work/Projects/ML_Projects/CaliforniaHousingCensusCase/src/utils/data_transformations.py:186\u001B[0m, in \u001B[0;36mpreprocess_data\u001B[0;34m(X, y, normalize_target, variables_with_outliers, preprocessor, verbose)\u001B[0m\n\u001B[1;32m    181\u001B[0m     preprocessor \u001B[38;5;241m=\u001B[39m get_preprocessor(\n\u001B[1;32m    182\u001B[0m         categorical_columns\u001B[38;5;241m=\u001B[39mcat_cols,\n\u001B[1;32m    183\u001B[0m         numerical_columns\u001B[38;5;241m=\u001B[39mnum_cols\n\u001B[1;32m    184\u001B[0m     )\n\u001B[1;32m    185\u001B[0m     \u001B[38;5;66;03m# Dummy variable\u001B[39;00m\n\u001B[0;32m--> 186\u001B[0m     \u001B[43mpreprocessor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit_transform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    187\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    188\u001B[0m     X \u001B[38;5;241m=\u001B[39m preprocessor\u001B[38;5;241m.\u001B[39mtransform(X\u001B[38;5;241m=\u001B[39mX)\n",
      "File \u001B[0;32m~/Work/Projects/ML_Projects/CaliforniaHousingCensusCase/venv/lib/python3.10/site-packages/sklearn/utils/_set_output.py:142\u001B[0m, in \u001B[0;36m_wrap_method_output.<locals>.wrapped\u001B[0;34m(self, X, *args, **kwargs)\u001B[0m\n\u001B[1;32m    140\u001B[0m \u001B[38;5;129m@wraps\u001B[39m(f)\n\u001B[1;32m    141\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapped\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m--> 142\u001B[0m     data_to_wrap \u001B[38;5;241m=\u001B[39m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    143\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data_to_wrap, \u001B[38;5;28mtuple\u001B[39m):\n\u001B[1;32m    144\u001B[0m         \u001B[38;5;66;03m# only wrap the first output for cross decomposition\u001B[39;00m\n\u001B[1;32m    145\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m (\n\u001B[1;32m    146\u001B[0m             _wrap_data_with_container(method, data_to_wrap[\u001B[38;5;241m0\u001B[39m], X, \u001B[38;5;28mself\u001B[39m),\n\u001B[1;32m    147\u001B[0m             \u001B[38;5;241m*\u001B[39mdata_to_wrap[\u001B[38;5;241m1\u001B[39m:],\n\u001B[1;32m    148\u001B[0m         )\n",
      "File \u001B[0;32m~/Work/Projects/ML_Projects/CaliforniaHousingCensusCase/venv/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py:727\u001B[0m, in \u001B[0;36mColumnTransformer.fit_transform\u001B[0;34m(self, X, y)\u001B[0m\n\u001B[1;32m    724\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_column_callables(X)\n\u001B[1;32m    725\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_remainder(X)\n\u001B[0;32m--> 727\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fit_transform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_fit_transform_one\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    729\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m result:\n\u001B[1;32m    730\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_update_fitted_transformers([])\n",
      "File \u001B[0;32m~/Work/Projects/ML_Projects/CaliforniaHousingCensusCase/venv/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py:658\u001B[0m, in \u001B[0;36mColumnTransformer._fit_transform\u001B[0;34m(self, X, y, func, fitted, column_as_strings)\u001B[0m\n\u001B[1;32m    652\u001B[0m transformers \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(\n\u001B[1;32m    653\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iter(\n\u001B[1;32m    654\u001B[0m         fitted\u001B[38;5;241m=\u001B[39mfitted, replace_strings\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, column_as_strings\u001B[38;5;241m=\u001B[39mcolumn_as_strings\n\u001B[1;32m    655\u001B[0m     )\n\u001B[1;32m    656\u001B[0m )\n\u001B[1;32m    657\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 658\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mParallel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mn_jobs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    659\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdelayed\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    660\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtransformer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mclone\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrans\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mfitted\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mtrans\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    661\u001B[0m \u001B[43m            \u001B[49m\u001B[43mX\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m_safe_indexing\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcolumn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    662\u001B[0m \u001B[43m            \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    663\u001B[0m \u001B[43m            \u001B[49m\u001B[43mweight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    664\u001B[0m \u001B[43m            \u001B[49m\u001B[43mmessage_clsname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mColumnTransformer\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    665\u001B[0m \u001B[43m            \u001B[49m\u001B[43mmessage\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_log_message\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43midx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mtransformers\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    666\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    667\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43midx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrans\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcolumn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mtransformers\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    668\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    669\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    670\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExpected 2D array, got 1D array instead\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mstr\u001B[39m(e):\n",
      "File \u001B[0;32m~/Work/Projects/ML_Projects/CaliforniaHousingCensusCase/venv/lib/python3.10/site-packages/sklearn/utils/parallel.py:63\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[0;34m(self, iterable)\u001B[0m\n\u001B[1;32m     58\u001B[0m config \u001B[38;5;241m=\u001B[39m get_config()\n\u001B[1;32m     59\u001B[0m iterable_with_config \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m     60\u001B[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001B[1;32m     61\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m delayed_func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m iterable\n\u001B[1;32m     62\u001B[0m )\n\u001B[0;32m---> 63\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43miterable_with_config\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Work/Projects/ML_Projects/CaliforniaHousingCensusCase/venv/lib/python3.10/site-packages/joblib/parallel.py:1098\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[0;34m(self, iterable)\u001B[0m\n\u001B[1;32m   1095\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterating \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m   1097\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend\u001B[38;5;241m.\u001B[39mretrieval_context():\n\u001B[0;32m-> 1098\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mretrieve\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1099\u001B[0m \u001B[38;5;66;03m# Make sure that we get a last message telling us we are done\u001B[39;00m\n\u001B[1;32m   1100\u001B[0m elapsed_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_start_time\n",
      "File \u001B[0;32m~/Work/Projects/ML_Projects/CaliforniaHousingCensusCase/venv/lib/python3.10/site-packages/joblib/parallel.py:975\u001B[0m, in \u001B[0;36mParallel.retrieve\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    973\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    974\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msupports_timeout\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[0;32m--> 975\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_output\u001B[38;5;241m.\u001B[39mextend(\u001B[43mjob\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m    976\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    977\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_output\u001B[38;5;241m.\u001B[39mextend(job\u001B[38;5;241m.\u001B[39mget())\n",
      "File \u001B[0;32m~/Work/Projects/ML_Projects/CaliforniaHousingCensusCase/venv/lib/python3.10/site-packages/joblib/_parallel_backends.py:567\u001B[0m, in \u001B[0;36mLokyBackend.wrap_future_result\u001B[0;34m(future, timeout)\u001B[0m\n\u001B[1;32m    564\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001B[39;00m\n\u001B[1;32m    565\u001B[0m \u001B[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001B[39;00m\n\u001B[1;32m    566\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 567\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfuture\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresult\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    568\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m CfTimeoutError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    569\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTimeoutError\u001B[39;00m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n",
      "File \u001B[0;32m/usr/lib/python3.10/concurrent/futures/_base.py:458\u001B[0m, in \u001B[0;36mFuture.result\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    456\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m CancelledError()\n\u001B[1;32m    457\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_state \u001B[38;5;241m==\u001B[39m FINISHED:\n\u001B[0;32m--> 458\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__get_result\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    459\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    460\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTimeoutError\u001B[39;00m()\n",
      "File \u001B[0;32m/usr/lib/python3.10/concurrent/futures/_base.py:403\u001B[0m, in \u001B[0;36mFuture.__get_result\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    401\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exception:\n\u001B[1;32m    402\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 403\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exception\n\u001B[1;32m    404\u001B[0m     \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    405\u001B[0m         \u001B[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001B[39;00m\n\u001B[1;32m    406\u001B[0m         \u001B[38;5;28mself\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[0;31mTypeError\u001B[0m: fit_transform() missing argument: y"
     ]
    }
   ],
   "source": [
    "vars_with_outliers = [\"median_income\", \"total_rooms\", \"total_bedrooms\", \"population\",\n",
    "                      \"median_income\", \"housing_median_age\", \"households\"]\n",
    "\n",
    "x_train, y_train, preprocessor, _ = preprocess_data(X=x_train, y=y_train, variables_with_outliers=vars_with_outliers)\n",
    "x_test, y_test, _, _ = preprocess_data(X=x_test, y=y_test, preprocessor=preprocessor, variables_with_outliers=vars_with_outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# X = x_train.drop('longitude', axis=1).copy()\n",
    "# x_test = x_test.drop('longitude', axis=1)\n",
    "X = x_train.copy()\n",
    "y = y_train.copy()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_train.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_test.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Simple Linear Regression"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lr = GridSearchCV(estimator=LinearRegression(n_jobs=-1),\n",
    "                  n_jobs=-1,\n",
    "                  verbose=1,\n",
    "                  param_grid={},\n",
    "                  cv=5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lr.fit(X=X, y=y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "metrics = add_metrics(metrics_report=metrics,\n",
    "                      model_name='LR_Simple',\n",
    "                      y_true=y_test,\n",
    "                      y_pred=lr.predict(x_test))\n",
    "\n",
    "print(f\"{metrics['LR_Simple']}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Linear Regression with Polynomial Features"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_polyn_pipe = Pipeline(steps=[\n",
    "    ('polynomail', PolynomialFeatures(degree=3, include_bias=False)),\n",
    "    ('lr', LinearRegression(n_jobs=-1))\n",
    "])\n",
    "\n",
    "lr_polynomial = GridSearchCV(\n",
    "    estimator=model_polyn_pipe,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    param_grid={},\n",
    "    cv=5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_polynomial.fit(X=X, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "metrics = add_metrics(metrics_report=metrics,\n",
    "                      model_name='LR_PolynEffects',\n",
    "                      y_true=y_test,\n",
    "                      y_pred=lr_polynomial.predict(x_test))\n",
    "\n",
    "print(f\"{metrics['LR_PolynEffects']}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Regression with Regularization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "l1_ratios = numpy.linspace(0.1, 0.9, 9)\n",
    "alphas = numpy.array([1e-5, 5e-5, 0.0001, 0.0005])\n",
    "\n",
    "lr_regularization = ElasticNetCV(\n",
    "    alphas=alphas,\n",
    "    l1_ratio=l1_ratios,\n",
    "    n_jobs=-1,\n",
    "    max_iter=int(1e4),\n",
    "    cv=5\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lr_regularization.fit(X=X, y=y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "metrics = add_metrics(metrics_report=metrics,\n",
    "                      model_name='Regularization',\n",
    "                      y_true=y_test,\n",
    "                      y_pred=lr_regularization.predict(x_test))\n",
    "\n",
    "print(f\"{metrics['Regularization']}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Processing data:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"LR_Simple\": {\n",
    "        \"MSE\": 6784237334.8747,\n",
    "        \"RMSE\": 82366.4819,\n",
    "        \"R2\": 0.4831,\n",
    "        \"MAE\": 59813.3505\n",
    "    },\n",
    "    \"LR_PolynEffects\": {\n",
    "        \"MSE\": 5496039866.1283,\n",
    "        \"RMSE\": 74135.2808,\n",
    "        \"R2\": 0.5813,\n",
    "        \"MAE\": 52709.0184\n",
    "    },\n",
    "    \"Regularization\": {\n",
    "        \"MSE\": 6784518279.5301,\n",
    "        \"RMSE\": 82368.1873,\n",
    "        \"R2\": 0.4831,\n",
    "        \"MAE\": 59803.6537\n",
    "    }\n",
    "}\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import json\n",
    "print(json.dumps(metrics, indent=4))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_test.mean(), y_test.median(), y_test.min(), y_test.max()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Insights and key findings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Next Steps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Author"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "<p>Author: Jose Pena</p>\n",
    "<p>Github: <a href=\"https://github.com/JoseJuan98\">JoseJuan98</a></p>"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Change Log\n",
    "| Date (YYYY-MM-DD) | Version | Changed By | Change Description   |\n",
    "|-------------------| ------- | ---------- | -------------------- |\n",
    "| 2022-11-27        | 1.0     | Jose       | First version        |\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
